Just a place to put down ideas.

- For modeling more complex effects: can we make the architecture more like the
circuit? For a tape delay, for instance, can we have our architecture have a
symbolic tape, tape reel, and input and output gain stage?

-For modeling time-based effects, can we hard code an internal clock parameter
into the network? Can we make this clock parameterizable to capture analog
error?

-Also for time-based effects, can we require a feedback buffer fed into the
network?

-Could it be more efficient to directly optimize a FIR filter with a sine
sweep, and then train the network to perform non-linear corrections? Would
that allow us to use a smaller network? Such an FIR would need to be
parameterizable by the effect controls. Does that thing even exist?

-Could we perform certain operations in the frequency domain? Would this
improve results and would it allow us to reduce the complexity of the
network?

-Can we implement this on the GPU? How parallelizable is this?



Notes so far:
-We need varied data. Not much of it, but varied. Loss is about quadruple on
guitars the network hasn't seen.
  -It may be that we just need quieter data in there? The set I recorded for
  current use is mostly just shredding because I assumed quiet playing was bad.
  -Or maybe something like 3 guitars and 2 basses instead of just 1 guitar
  and 1 bass.
-We need to train this on a cloud machine with a GPU.
